{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: ML Pipeline - Iris Classifier\n",
    "\n",
    "> **AI Solutions Architect Portfolio** | Day 1, Session 2\n",
    ">\n",
    "> A complete ML pipeline demonstrating: data loading, exploration, preparation, training, evaluation, and explainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Import Libraries\n# Every ML project starts with these\nimport pandas as pd                  # Data manipulation (think: spreadsheets in code)\nimport numpy as np                   # Math operations (think: calculator on steroids)\nimport matplotlib.pyplot as plt      # Visualization (think: chart maker)\nimport seaborn as sns                # Pretty visualizations (think: chart maker, but prettier)\n\nfrom sklearn.datasets import load_iris          # Our dataset\nfrom sklearn.model_selection import train_test_split  # Split data for training/testing\nfrom sklearn.preprocessing import StandardScaler      # Normalize features\nfrom sklearn.ensemble import RandomForestClassifier   # Our model\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(\"Libraries loaded. Ready to build.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Explore the Data\n",
    "# Load the Iris dataset - 150 flowers, 4 measurements each, 3 species\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to a DataFrame (like a spreadsheet)\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target  # Add the label (0, 1, or 2 = three species)\n",
    "df['species_name'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# What does our data look like?\n",
    "print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nFeatures (inputs): {iris.feature_names}\")\n",
    "print(f\"Labels (outputs): {iris.target_names}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Visualize the Data (Architect's Eye)\n",
    "# As a Solutions Architect, you need to understand the data BEFORE modeling\n",
    "# This tells you: are the classes separable? Are features useful?\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Iris Dataset - Feature Distributions by Species', fontsize=14)\n",
    "\n",
    "for i, feature in enumerate(iris.feature_names):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    for species_id, species_name in enumerate(iris.target_names):\n",
    "        subset = df[df['species'] == species_id]\n",
    "        ax.hist(subset[feature], alpha=0.6, label=species_name, bins=15)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# WHAT TO NOTICE: If the colors separate cleanly, that feature is useful.\n",
    "# If they overlap completely, that feature won't help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prepare the Data (The Pipeline Begins)\n",
    "# STEP 1: Separate features (X) from labels (y)\n",
    "X = df[iris.feature_names]  # The 4 measurements (inputs)\n",
    "y = df['species']            # The species to predict (output)\n",
    "\n",
    "# STEP 2: Split into training and testing sets\n",
    "# 80% for training, 20% for testing - the model never sees the test data during training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42  # random_state = reproducible results\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set:  {X_test.shape[0]} samples\")\n",
    "\n",
    "# STEP 3: Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Learn scaling from training data\n",
    "X_test_scaled = scaler.transform(X_test)          # Apply same scaling to test data\n",
    "\n",
    "# WHY: fit_transform on training, just transform on testing.\n",
    "# If you fit on test data too, you're leaking future information into the model.\n",
    "# This is called \"data leakage\" - a common mistake the SA should catch.\n",
    "print(\"\\nFeatures normalized. Pipeline step 1 complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train the Model\n",
    "# Random Forest = a collection of decision trees that vote on the answer\n",
    "# Think of it as a panel of experts. Each tree sees a random subset of data,\n",
    "# makes its own decision, and the majority vote wins.\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,    # 100 decision trees in our forest\n",
    "    random_state=42      # Reproducible results\n",
    ")\n",
    "\n",
    "# Train the model - this is where it learns patterns\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained on 120 samples.\")\n",
    "print(\"Now let's see how it performs on the 30 samples it's never seen...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate Performance\n",
    "# Make predictions on the test set (data the model has never seen)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# How accurate?\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.1%}\")\n",
    "print(f\"\\nDetailed Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "# Confusion Matrix - shows exactly where the model gets confused\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Where Does the Model Get It Wrong?')\n",
    "plt.show()\n",
    "\n",
    "# ARCHITECT'S QUESTION: Is this accuracy good enough for the business problem?\n",
    "# 100% on Iris is easy. Real-world problems are messier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Feature Importance (The Explainability Layer)\n",
    "# Random Forests can tell us which features mattered most\n",
    "\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance - What Drives the Prediction?')\n",
    "plt.show()\n",
    "\n",
    "# ARCHITECT INSIGHT: If one feature dominates, the model is simple.\n",
    "# If importance is spread evenly, the relationships are complex.\n",
    "# This shapes your architecture decisions (latency, compute needs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: The Full Pipeline Diagram\n",
    "# Let's visualize what we just built - this is the architecture artifact\n",
    "\n",
    "pipeline_text = \"\"\"\n",
    "======================================================================\n",
    "                   ML PIPELINE ARCHITECTURE                      \n",
    "                   Project 1: Iris Classifier                    \n",
    "======================================================================\n",
    "                                                                  \n",
    "  +------------+   +------------+   +------------+              \n",
    "  | 1. DATA    |-->| 2. PREPARE |-->| 3. SPLIT   |              \n",
    "  | Load Iris  |   | Clean &    |   | 80% Train  |              \n",
    "  | 150 rows   |   | Explore    |   | 20% Test   |              \n",
    "  | 4 features |   | Visualize  |   |            |              \n",
    "  +------------+   +------------+   +-----+------+              \n",
    "                                          |                      \n",
    "                              +-----------+-----------+          \n",
    "                              v                       v          \n",
    "                    +------------+           +------------+      \n",
    "                    | 4. SCALE   |           | Hold for   |      \n",
    "                    | Normalize  |           | testing    |      \n",
    "                    | features   |           | (unseen)   |      \n",
    "                    +-----+------+           +-----+------+      \n",
    "                          v                        |              \n",
    "                    +------------+                 |              \n",
    "                    | 5. TRAIN   |                 |              \n",
    "                    | Random     |                 |              \n",
    "                    | Forest     |                 |              \n",
    "                    | (100 trees)|                 |              \n",
    "                    +-----+------+                 |              \n",
    "                          v                        v              \n",
    "                    +------------+           +------------+      \n",
    "                    | 6. PREDICT |---------->| 7. EVALUATE|      \n",
    "                    | on test    |           | Accuracy   |      \n",
    "                    | data       |           | Confusion  |      \n",
    "                    |            |           | Matrix     |      \n",
    "                    +------------+           +-----+------+      \n",
    "                                                   v              \n",
    "                                            +------------+       \n",
    "                                            | 8. EXPLAIN |       \n",
    "                                            | Feature    |       \n",
    "                                            | Importance |       \n",
    "                                            +------------+       \n",
    "                                                                  \n",
    "======================================================================\n",
    "\"\"\"\n",
    "print(pipeline_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}